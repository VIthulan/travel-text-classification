{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_classification_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TkWr6jcAPqy",
        "outputId": "55730cbc-a019-4127-b42c-e78b2a1fddd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/c1/015648a2186b25c6de79d15bec40d3d946fcf1dd5067d1c1b28009506486/bert-for-tf2-0.14.6.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 1.8MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.6-cp36-none-any.whl size=30318 sha256=513f594220fb19e4af7ca42278642f8563e463331da7ea450b544690ee428135\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/a0/b4/75b0601ebaa41e517a797fe9cea119c789664c8408f8a74ae9\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=4f35d828aa9ffe2eddcc191c6df86f39a70839567bfe6169d43e2392e08bb2f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=266ec760d05fecb04804ff233a2ff453ef8963e4248442ea4e63f57d845eb17b\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.6 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoyzMo-HAgmQ",
        "outputId": "928c68b5-3e8a-4b1f-8bc7-63201dc2a805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "from tensorflow.keras.models import  Model\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.3.0\n",
            "Hub version:  0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk31Scz4Ak5d"
      },
      "source": [
        "bert_layer=hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=True)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXRpAptGAxyg"
      },
      "source": [
        "MAX_SEQ_LEN=128\n",
        "input_word_ids = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "input_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "segment_ids = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1180J0vBHYv"
      },
      "source": [
        "def get_masks(tokens, max_seq_length):\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLXLfzN2BJPV"
      },
      "source": [
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYK0L95fBYiW"
      },
      "source": [
        "FullTokenizer=bert.bert_tokenization.FullTokenizer\n",
        "\n",
        "vocab_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "\n",
        "do_lower_case=bert_layer.resolved_object.do_lower_case.numpy()\n",
        "\n",
        "tokenizer=FullTokenizer(vocab_file,do_lower_case)\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8iX2XDzBZz9"
      },
      "source": [
        "import pandas as pd\n",
        "col_names = ['questions', 'a', 'b']\n",
        "data_df = pd.read_csv(\"https://raw.githubusercontent.com/VIthulan/travel-text-classification/master/data/5000TravelQuestionsDataset.csv\", error_bad_lines=False,header=None, names=col_names, encoding='latin-1')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fXiVNF3BvKw"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def remove_stopwords(text):\n",
        "  word_tokens = nltk.word_tokenize(text) \n",
        "  filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
        "  return \" \".join(filtered_sentence)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d4-_CjaBvUf"
      },
      "source": [
        "# Remove all the special characters\n",
        "data_df['processed_questions'] = data_df['questions'].str.replace(r'\\W', ' ')\n",
        "    # remove all single characters\n",
        "data_df['processed_questions'] = data_df['processed_questions'].str.replace(r'\\s+[a-zA-Z]\\s+', ' ')\n",
        "    # Remove single characters from the start\n",
        "data_df['processed_questions'] = data_df['questions'].str.replace(r'\\^[a-zA-Z]\\s+', ' ')\n",
        "    # Substituting multiple spaces with single space\n",
        "data_df['processed_questions'] = data_df['questions'].str.replace(r'\\s+', ' ')\n",
        "    # Removing prefixed 'b'\n",
        "data_df['processed_questions'] = data_df['questions'].str.replace(r'^b\\s+', '')\n",
        "    # Remove leading, trailing spaces\n",
        "data_df['processed_questions'] = data_df['questions'].str.strip()\n",
        "# Stop word removal\n",
        "data_df['sw_removed_questions'] = data_df.processed_questions.apply(remove_stopwords)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPMu7-MpB6Op"
      },
      "source": [
        "# Remove all the special characters\n",
        "data_df['processed_a'] = data_df['a'].str.replace(r'\\W', ' ')\n",
        "    # remove all single characters\n",
        "data_df['processed_a'] = data_df['a'].str.replace(r'\\s+[a-zA-Z]\\s+', ' ')\n",
        "    # Remove single characters from the start\n",
        "data_df['processed_a'] = data_df['a'].str.replace(r'\\^[a-zA-Z]\\s+', ' ')\n",
        "    # Substituting multiple spaces with single space\n",
        "data_df['processed_a'] = data_df['a'].str.replace(r'\\s+', ' ')\n",
        "    # Removing prefixed 'b'\n",
        "data_df['processed_a'] = data_df['a'].str.replace(r'^b\\s+', '')\n",
        "    # Remove leading, trailing spaces\n",
        "data_df['processed_a'] = data_df['a'].str.strip()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miPKAALICC76"
      },
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "  lem = [lemmatizer.lemmatize(w, pos=\"v\") for w in nltk.word_tokenize(text)]\n",
        "  return \" \".join(lem)\n",
        "\n",
        "data_df[\"question_lemmatized_sw\"] = data_df.sw_removed_questions.apply(lemmatize_text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiS8Uo7hB7l7",
        "outputId": "356f54aa-b381-4cc8-a3f2-af387baf208b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "data_df.tail(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>processed_questions</th>\n",
              "      <th>sw_removed_questions</th>\n",
              "      <th>processed_a</th>\n",
              "      <th>question_lemmatized_sw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4990</th>\n",
              "      <td>Any self sevice laundries in Costa Teguise?</td>\n",
              "      <td>TGU</td>\n",
              "      <td>TGULAU</td>\n",
              "      <td>Any self sevice laundries in Costa Teguise?</td>\n",
              "      <td>Any self sevice laundries Costa Teguise ?</td>\n",
              "      <td>TGU</td>\n",
              "      <td>Any self sevice laundries Costa Teguise ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>What are the reviews on Firefly Car Rental?</td>\n",
              "      <td>TRS</td>\n",
              "      <td>TRSRNT</td>\n",
              "      <td>What are the reviews on Firefly Car Rental?</td>\n",
              "      <td>What reviews Firefly Car Rental ?</td>\n",
              "      <td>TRS</td>\n",
              "      <td>What review Firefly Car Rental ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>What are the resorts in Majorca do group boat ...</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMRES</td>\n",
              "      <td>What are the resorts in Majorca do group boat ...</td>\n",
              "      <td>What resorts Majorca group boat trips ?</td>\n",
              "      <td>ACM</td>\n",
              "      <td>What resort Majorca group boat trip ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>What are the reviews on Hotel Bagues?</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMHOT</td>\n",
              "      <td>What are the reviews on Hotel Bagues?</td>\n",
              "      <td>What reviews Hotel Bagues ?</td>\n",
              "      <td>ACM</td>\n",
              "      <td>What review Hotel Bagues ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>What is a recommendation for a reasonably pric...</td>\n",
              "      <td>TRS</td>\n",
              "      <td>TRSRNT</td>\n",
              "      <td>What is a recommendation for a reasonably pric...</td>\n",
              "      <td>What recommendation reasonably priced car rent...</td>\n",
              "      <td>TRS</td>\n",
              "      <td>What recommendation reasonably price car renta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>What is the best area to be based for sightsee...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "      <td>What is the best area to be based for sightsee...</td>\n",
              "      <td>What best area based sightseeing Palma ?</td>\n",
              "      <td>TTD</td>\n",
              "      <td>What best area base sightsee Palma ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>What are the good value traditional bars and r...</td>\n",
              "      <td>FOD</td>\n",
              "      <td>FODBAR</td>\n",
              "      <td>What are the good value traditional bars and r...</td>\n",
              "      <td>What good value traditional bars restaurants B...</td>\n",
              "      <td>FOD</td>\n",
              "      <td>What good value traditional bar restaurants Ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>What are the hotels near Alicante bus station?</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMHOT</td>\n",
              "      <td>What are the hotels near Alicante bus station?</td>\n",
              "      <td>What hotels near Alicante bus station ?</td>\n",
              "      <td>ACM</td>\n",
              "      <td>What hotels near Alicante bus station ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Where to stay in La Gomera to mountain biking?</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSPO</td>\n",
              "      <td>Where to stay in La Gomera to mountain biking?</td>\n",
              "      <td>Where stay La Gomera mountain biking ?</td>\n",
              "      <td>TTD</td>\n",
              "      <td>Where stay La Gomera mountain bike ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Is it possible to take a train trip from Santi...</td>\n",
              "      <td>TRS</td>\n",
              "      <td>TRSTRN</td>\n",
              "      <td>Is it possible to take a train trip from Santi...</td>\n",
              "      <td>Is possible take train trip Santiago Madrid ?</td>\n",
              "      <td>TRS</td>\n",
              "      <td>Is possible take train trip Santiago Madrid ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              questions  ...                             question_lemmatized_sw\n",
              "4990        Any self sevice laundries in Costa Teguise?  ...          Any self sevice laundries Costa Teguise ?\n",
              "4991        What are the reviews on Firefly Car Rental?  ...                   What review Firefly Car Rental ?\n",
              "4992  What are the resorts in Majorca do group boat ...  ...              What resort Majorca group boat trip ?\n",
              "4993              What are the reviews on Hotel Bagues?  ...                         What review Hotel Bagues ?\n",
              "4994  What is a recommendation for a reasonably pric...  ...  What recommendation reasonably price car renta...\n",
              "4995  What is the best area to be based for sightsee...  ...               What best area base sightsee Palma ?\n",
              "4996  What are the good value traditional bars and r...  ...  What good value traditional bar restaurants Ba...\n",
              "4997     What are the hotels near Alicante bus station?  ...            What hotels near Alicante bus station ?\n",
              "4998     Where to stay in La Gomera to mountain biking?  ...               Where stay La Gomera mountain bike ?\n",
              "4999  Is it possible to take a train trip from Santi...  ...      Is possible take train trip Santiago Madrid ?\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1ZuNXdsDFn-"
      },
      "source": [
        "def create_single_input(sentence,MAX_LEN):\n",
        "  \n",
        "  stokens = tokenizer.tokenize(sentence)\n",
        "  \n",
        "  stokens = stokens[:MAX_LEN]\n",
        "  \n",
        "  stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        " \n",
        "  ids = get_ids(stokens, tokenizer, MAX_SEQ_LEN)\n",
        "  masks = get_masks(stokens, MAX_SEQ_LEN)\n",
        "  segments = get_segments(stokens, MAX_SEQ_LEN)\n",
        "\n",
        "  return ids,masks,segments\n",
        "\n",
        "def create_input_array(sentences):\n",
        "\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        "\n",
        "  for sentence in tqdm(sentences,position=0, leave=True):\n",
        "  \n",
        "    ids,masks,segments=create_single_input(sentence,MAX_SEQ_LEN-2)\n",
        "\n",
        "    input_ids.append(ids)\n",
        "    input_masks.append(masks)\n",
        "    input_segments.append(segments)\n",
        "\n",
        "  return [np.asarray(input_ids, dtype=np.int32), \n",
        "            np.asarray(input_masks, dtype=np.int32), \n",
        "            np.asarray(input_segments, dtype=np.int32)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRWrB0t6Cl9C"
      },
      "source": [
        "def get_model():\n",
        "  x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  out = tf.keras.layers.Dense(7, activation=\"softmax\", name=\"dense_output\")(x)\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "        inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjqEwuV_DO-x",
        "outputId": "e624979a-0301-4da1-e37b-bc232a90bf3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "create_input_array(\"Is Corona Spreading again?\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:00<00:00, 12304.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 101, 1045,  102, ...,    0,    0,    0],\n",
              "        [ 101, 1055,  102, ...,    0,    0,    0],\n",
              "        [ 101,  102,    0, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 1045,  102, ...,    0,    0,    0],\n",
              "        [ 101, 1050,  102, ...,    0,    0,    0],\n",
              "        [ 101, 1029,  102, ...,    0,    0,    0]], dtype=int32),\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNSFqan-DpJz",
        "outputId": "073efa57-93af-4a49-86be-ea5f52a8b9e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs=create_input_array(data_df.question_lemmatized_sw.values)\n",
        "train_y = pd.get_dummies(data_df['processed_a']).values"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:00<00:00, 6156.25it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIn_WiDzGiSU",
        "outputId": "5aa1bdf2-e521-477a-ab43-f66e8d555c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 101, 2054, 2569, ...,    0,    0,    0],\n",
              "        [ 101, 2054, 2194, ...,    0,    0,    0],\n",
              "        [ 101, 2003, 3647, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 2054, 9275, ...,    0,    0,    0],\n",
              "        [ 101, 2073, 2994, ...,    0,    0,    0],\n",
              "        [ 101, 2003, 2825, ...,    0,    0,    0]], dtype=int32),\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71GASiKDbJo9"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(data_df['processed_a'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTum9M0jEOSa"
      },
      "source": [
        "# from sklearn.model_selection import KFold\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "# fold = 0\n",
        "# accuracies = []\n",
        "# for train_index, test_index in cv.split(inputs):\n",
        "#     fold += 1\n",
        "#     X_train, X_test = inputs[train_index], inputs[test_index]\n",
        "#     y_train, y_test = train_y[train_index], train_y[test_index]\n",
        "#     print(\"***************************************************************\")\n",
        "#     print(\"Beginning fold: \", fold)\n",
        "#     model = get_model()\n",
        "#     model.fit(X_train,y_train,epochs=10,batch_size=32,validation_split=0.2,shuffle=True)\n",
        "#     predictions = model.predict(X_test)\n",
        "#     print(predictions)\n",
        "#     break\n",
        "# print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTJPe797suHE",
        "outputId": "aee4e19a-9838-46a4-913b-3a548ccd44e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# model = get_model()\n",
        "# model.fit(inputs,train_y,epochs=10,batch_size=32,validation_split=0.2,shuffle=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "125/125 [==============================] - 102s 816ms/step - loss: 2.0462 - accuracy: 0.2075 - val_loss: 1.8708 - val_accuracy: 0.1820\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 108s 862ms/step - loss: 1.8135 - accuracy: 0.2365 - val_loss: 1.9954 - val_accuracy: 0.0340\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 107s 855ms/step - loss: 1.8100 - accuracy: 0.2188 - val_loss: 1.8754 - val_accuracy: 0.1820\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 107s 855ms/step - loss: 1.7957 - accuracy: 0.2307 - val_loss: 1.8228 - val_accuracy: 0.3340\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 107s 860ms/step - loss: 1.7903 - accuracy: 0.2320 - val_loss: 1.8577 - val_accuracy: 0.0340\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 107s 859ms/step - loss: 1.7875 - accuracy: 0.2365 - val_loss: 1.9658 - val_accuracy: 0.0340\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 107s 859ms/step - loss: 1.7911 - accuracy: 0.2310 - val_loss: 1.8628 - val_accuracy: 0.2510\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 107s 858ms/step - loss: 1.7826 - accuracy: 0.2445 - val_loss: 1.8461 - val_accuracy: 0.1820\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 107s 859ms/step - loss: 1.7820 - accuracy: 0.2485 - val_loss: 1.8202 - val_accuracy: 0.1820\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 107s 858ms/step - loss: 1.7766 - accuracy: 0.2508 - val_loss: 1.8305 - val_accuracy: 0.1820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2b5ebb8898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-RbSskVXkDp"
      },
      "source": [
        "# Updated model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOwix4g3XjSn"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import os\n",
        "os.environ['TFHUB_DOWNLOAD_PROGRESS'] = \"1\"\n",
        "\n",
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n",
        "\n",
        "def tokenize_reviews(text_reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKCFS1M6akON"
      },
      "source": [
        "tokenized_questions = [tokenize_reviews(qu) for qu in data_df['questions'].values]\n",
        "reviews_with_len = [[question, y[i], len(question)] for i, question in enumerate(tokenized_questions)]\n",
        "\n",
        "import random\n",
        "random.shuffle(reviews_with_len)\n",
        "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfg4Hz-EbmnJ"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "class TEXT_MODEL(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        \n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtFttdUpbrSf"
      },
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 10\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 10"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu0noivgbvHm"
      },
      "source": [
        "def create_and_compile_bert():\n",
        "    text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                            embedding_dimensions=EMB_DIM,\n",
        "                            cnn_filters=CNN_FILTERS,\n",
        "                            dnn_units=DNN_UNITS,\n",
        "                            model_output_classes=OUTPUT_CLASSES,\n",
        "                            dropout_rate=DROPOUT_RATE)\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])\n",
        "    \n",
        "    return text_model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwMrWNCXbxwQ",
        "outputId": "ad2d60ea-f1e5-4190-fe09-c6a5fa09af41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "create_and_compile_bert()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TEXT_MODEL at 0x7fe754719f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCByC3iZb2AH",
        "outputId": "c7027756-c74d-49ff-ae32-3da0400359b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import math\n",
        "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "    \n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "fold = 0\n",
        "accuracies = []\n",
        "for i in range(10):\n",
        "    fold += 1\n",
        "    \n",
        "    text_model = create_and_compile_bert()\n",
        "    \n",
        "    batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "    test_data = batched_dataset.take(TEST_BATCHES)\n",
        "    train_data = batched_dataset.skip(TEST_BATCHES)\n",
        "    \n",
        "\n",
        "    text_model.fit(train_data, epochs=NB_EPOCHS)\n",
        "    results = text_model.evaluate(test_data)\n",
        "    print(\"-------\")\n",
        "    print(\"Accuracy: %s \"%results[1])\n",
        "    print(\"======================================\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 1.4198 - sparse_categorical_accuracy: 0.4712\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.4679 - sparse_categorical_accuracy: 0.8527\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.1411 - sparse_categorical_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0374 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0200 - sparse_categorical_accuracy: 0.9956\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 6.9946e-04 - sparse_categorical_accuracy: 1.0000\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7755 - sparse_categorical_accuracy: 0.8313\n",
            "-------\n",
            "Accuracy: 0.831250011920929 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 1.3937 - sparse_categorical_accuracy: 0.4869\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.4584 - sparse_categorical_accuracy: 0.8529\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.1462 - sparse_categorical_accuracy: 0.9580\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0392 - sparse_categorical_accuracy: 0.9920\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0163 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 8.7142e-04 - sparse_categorical_accuracy: 1.0000\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6824 - sparse_categorical_accuracy: 0.8521\n",
            "-------\n",
            "Accuracy: 0.8520833253860474 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 74ms/step - loss: 1.4369 - sparse_categorical_accuracy: 0.4739\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.4941 - sparse_categorical_accuracy: 0.8451\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 74ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9558\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 11s 74ms/step - loss: 0.0495 - sparse_categorical_accuracy: 0.9881\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0028 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 9.4327e-04 - sparse_categorical_accuracy: 1.0000\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6887 - sparse_categorical_accuracy: 0.8438\n",
            "-------\n",
            "Accuracy: 0.84375 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 1.4392 - sparse_categorical_accuracy: 0.4670\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.4622 - sparse_categorical_accuracy: 0.8546\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.1499 - sparse_categorical_accuracy: 0.9571\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 8.2981e-04 - sparse_categorical_accuracy: 1.0000\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6489 - sparse_categorical_accuracy: 0.8521\n",
            "-------\n",
            "Accuracy: 0.8520833253860474 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 1.4043 - sparse_categorical_accuracy: 0.4914\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 74ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.8584\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9622\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0393 - sparse_categorical_accuracy: 0.9916\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0162 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0014 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9996\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6689 - sparse_categorical_accuracy: 0.8438\n",
            "-------\n",
            "Accuracy: 0.84375 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 1.3724 - sparse_categorical_accuracy: 0.4954\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.4421 - sparse_categorical_accuracy: 0.8595\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 11s 75ms/step - loss: 0.1397 - sparse_categorical_accuracy: 0.9604\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0382 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0146 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0022 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0023 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9989\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6523 - sparse_categorical_accuracy: 0.8500\n",
            "-------\n",
            "Accuracy: 0.8500000238418579 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 1.4244 - sparse_categorical_accuracy: 0.4750\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.4645 - sparse_categorical_accuracy: 0.8500\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9619\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0423 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0169 - sparse_categorical_accuracy: 0.9960\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0020 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 9.9591e-04 - sparse_categorical_accuracy: 0.9998\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7647 - sparse_categorical_accuracy: 0.8417\n",
            "-------\n",
            "Accuracy: 0.8416666388511658 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 11s 75ms/step - loss: 1.4128 - sparse_categorical_accuracy: 0.4836\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.4625 - sparse_categorical_accuracy: 0.8518\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9582\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9905\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9956\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9987\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6868 - sparse_categorical_accuracy: 0.8521\n",
            "-------\n",
            "Accuracy: 0.8520833253860474 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 1.4338 - sparse_categorical_accuracy: 0.4739\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 11s 75ms/step - loss: 0.4832 - sparse_categorical_accuracy: 0.8485\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.1483 - sparse_categorical_accuracy: 0.9549\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0475 - sparse_categorical_accuracy: 0.9889\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0196 - sparse_categorical_accuracy: 0.9949\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0019 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 9.9769e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0012 - sparse_categorical_accuracy: 0.9998\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7142 - sparse_categorical_accuracy: 0.8417\n",
            "-------\n",
            "Accuracy: 0.8416666388511658 \n",
            "======================================\n",
            "Epoch 1/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 1.4170 - sparse_categorical_accuracy: 0.4812\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.4486 - sparse_categorical_accuracy: 0.8573\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.1414 - sparse_categorical_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 10s 72ms/step - loss: 0.0441 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 10s 73ms/step - loss: 0.0019 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 11s 74ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9996\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7708 - sparse_categorical_accuracy: 0.8375\n",
            "-------\n",
            "Accuracy: 0.8374999761581421 \n",
            "======================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOGJkek1gXiY",
        "outputId": "cecfab28-9925-44ef-fc66-3404e624cb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "prediction = text_model.predict(test_data)\n",
        "print(prediction)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.2401089e-06 3.4720811e-06 2.0220501e-05 ... 3.1581802e-08\n",
            "  1.1482370e-08 8.4627096e-09]\n",
            " [7.4915340e-07 1.8612885e-05 9.9998045e-01 ... 4.9821340e-13\n",
            "  1.8031030e-12 2.5423268e-12]\n",
            " [2.3011236e-05 4.0550135e-06 1.1356462e-03 ... 8.0085734e-09\n",
            "  3.8873309e-09 4.2844079e-09]\n",
            " ...\n",
            " [1.4346844e-04 4.9850113e-10 1.4941151e-06 ... 2.5226081e-09\n",
            "  1.0789096e-09 5.4445454e-10]\n",
            " [7.8892208e-09 1.2184405e-07 3.2098523e-08 ... 8.2881195e-13\n",
            "  2.3522812e-13 2.3358862e-13]\n",
            " [9.9934047e-01 2.6382082e-05 4.2501828e-04 ... 8.4977053e-10\n",
            "  3.0907494e-09 7.7335599e-10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6hI99fFgfT_"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def print_report(y_test, y_pred):\n",
        "    # Classification Report\n",
        "    print(classification_report(y_test,y_pred))\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)*100\n",
        "    print('Accuracy score: %.3f' % acc)\n",
        "\n",
        "    print('F1 Score: %.3f' % f1_score(y_test, y_pred, average='weighted'))\n",
        "    \n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confustion matrix: \\n{}\".format(cm))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ChhzWKgrqY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}