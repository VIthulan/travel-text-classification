{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KU4IREGFnRp",
        "outputId": "e5b33fc6-6b57-4e2b-93f0-2da682151f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.datasets import load_files\n",
        "nltk.download('stopwords')\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk import pos_tag\n",
        "from nltk.tag.crf import CRFTagger\n",
        "from nltk.corpus import brown\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIPwXAbXFnxw",
        "outputId": "833dc813-9c5e-40d0-f631-39f6f80dbc4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pip install python-crfsuite"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-crfsuite in /usr/local/lib/python3.6/dist-packages (0.9.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L-mr_8jUe8B"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNLRnZboFnR2"
      },
      "source": [
        "col_names = ['questions', 'a', 'b']\n",
        "data_df = pd.read_csv(\"https://raw.githubusercontent.com/VIthulan/travel-text-classification/master/data/5000TravelQuestionsDataset.csv\", error_bad_lines=False,header=None, names=col_names, encoding='latin-1')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPpfyHXQFnR8",
        "outputId": "8b93e355-19fb-4ed5-e564-686473098e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data_df['questions']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       What are the special things we (husband and me...\n",
              "1       What are the companies which organize shark fe...\n",
              "2       Is it safe for female traveller to go alone to...\n",
              "3       What are the best places around Cape Town for ...\n",
              "4       What are the best places to stay for a family ...\n",
              "                              ...                        \n",
              "4995    What is the best area to be based for sightsee...\n",
              "4996    What are the good value traditional bars and r...\n",
              "4997       What are the hotels near Alicante bus station?\n",
              "4998       Where to stay in La Gomera to mountain biking?\n",
              "4999    Is it possible to take a train trip from Santi...\n",
              "Name: questions, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-IrOJm-UVxq"
      },
      "source": [
        "# Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqIAXyadS8-G"
      },
      "source": [
        "    # Remove all the special characters\n",
        "data_df['processed_questions'] = data_df['questions'].str.replace(r'\\W', ' ')\n",
        "    # remove all single characters\n",
        "data_df['processed_questions'] = data_df['processed_questions'].str.replace(r'\\s+[a-zA-Z]\\s+', ' ')\n",
        "    # Remove single characters from the start\n",
        "data_df['processed_questions'] = data_df['questions'].str.replace(r'\\^[a-zA-Z]\\s+', ' ')\n",
        "    # Substituting multiple spaces with single space\n",
        "data_df['processed_questions'] = data_df['questions'].str.replace(r'\\s+', ' ')\n",
        "    # Removing prefixed 'b'\n",
        "data_df['processed_questions'] = data_df['questions'].str.replace(r'^b\\s+', '')\n",
        "    # Remove leading, trailing spaces\n",
        "data_df['processed_questions'] = data_df['questions'].str.strip()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjBy4_OAUNNC",
        "outputId": "d2d6b0c6-d93c-4889-bba7-92b6d8c91f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data_df['processed_questions']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       What are the special things we (husband and me...\n",
              "1       What are the companies which organize shark fe...\n",
              "2       Is it safe for female traveller to go alone to...\n",
              "3       What are the best places around Cape Town for ...\n",
              "4       What are the best places to stay for a family ...\n",
              "                              ...                        \n",
              "4995    What is the best area to be based for sightsee...\n",
              "4996    What are the good value traditional bars and r...\n",
              "4997       What are the hotels near Alicante bus station?\n",
              "4998       Where to stay in La Gomera to mountain biking?\n",
              "4999    Is it possible to take a train trip from Santi...\n",
              "Name: processed_questions, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ1jKjccehzz"
      },
      "source": [
        "## Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhXikcjV_EMZ",
        "outputId": "9f11b54b-f2db-494b-bfdf-260a9a8fd6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgCLhhWmZQAd"
      },
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "  lem = [lemmatizer.lemmatize(w, pos=\"v\") for w in nltk.word_tokenize(text)]\n",
        "  return \" \".join(lem)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blLt_44caWZI"
      },
      "source": [
        "data_df[\"question_lemmatized\"] = data_df.processed_questions.apply(lemmatize_text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CEXVWJdcqAG",
        "outputId": "a434d394-a011-41c8-afdc-5fb9ab0d5fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data_df[\"question_lemmatized\"]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       What be the special things we ( husband and me...\n",
              "1       What be the company which organize shark feed ...\n",
              "2       Is it safe for female traveller to go alone to...\n",
              "3       What be the best place around Cape Town for sa...\n",
              "4       What be the best place to stay for a family to...\n",
              "                              ...                        \n",
              "4995    What be the best area to be base for sightsee ...\n",
              "4996    What be the good value traditional bar and res...\n",
              "4997       What be the hotels near Alicante bus station ?\n",
              "4998        Where to stay in La Gomera to mountain bike ?\n",
              "4999    Is it possible to take a train trip from Santi...\n",
              "Name: question_lemmatized, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQH0lfD1MNmx"
      },
      "source": [
        "## POS Tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5r-TRK8-coM"
      },
      "source": [
        "def pos_tagger(text):\n",
        "    pos_tagged = [ r[1] for r in pos_tag(nltk.word_tokenize(text))] \n",
        "    return ' '.join(pos_tagged)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THHonJS4-3KG"
      },
      "source": [
        "data_df[\"question_pos_t\"] = data_df.processed_questions.apply(pos_tagger)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxlpt7DZDoEs"
      },
      "source": [
        "# brown_tags = brown.tagged_sents(categories='hobbies')\n",
        "#  crf = CRFTagger()\n",
        "# crf.train(brown_tags,'model.crf.tagger')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3XPfAIaJZ_h",
        "outputId": "5d661095-01ad-47b0-d760-9e67769469a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data_df[\"question_pos_t\"]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       WP VBP DT JJ NNS PRP ( NN CC PRP ) MD VB IN DT...\n",
              "1             WP VBP DT NNS WDT VBP NN NN NNS IN NN NNS .\n",
              "2               VBZ PRP JJ IN JJ NN TO VB RB TO NNP NNP .\n",
              "3                    WP VBP DT JJS NNS IN NNP NNP IN NN .\n",
              "4       WP VBP DT JJS NNS TO VB IN DT NN TO VB RB IN NN .\n",
              "                              ...                        \n",
              "4995           WP VBZ DT JJS NN TO VB VBN IN VBG IN NNP .\n",
              "4996               WP VBP DT JJ NN JJ NNS CC NNS IN NNP .\n",
              "4997                         WP VBP DT NNS IN NNP NN NN .\n",
              "4998                      WRB TO VB IN NNP NNP TO VB NN .\n",
              "4999            VBZ PRP JJ TO VB DT NN NN IN NNP IN NNP .\n",
              "Name: question_pos_t, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW8hNuUXMQni"
      },
      "source": [
        "## Headword extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMRbML-tMboD"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def head_word_tokenizer(text):\n",
        "    head_words = []\n",
        "    for token in nlp(text):\n",
        "        if token.dep_ == \"nsubj\" or token.dep_ == \"nsubjpass\":\n",
        "            head_words.append(token.text)\n",
        "            head_words.append(token.head.text)\n",
        "    return head_words"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOS2ayUWMlXT"
      },
      "source": [
        "# head_words_vectorizer = CountVectorizer(tokenizer = head_word_tokenizer,max_features=100,stop_words=stopwords.words('english'))\n",
        "# head_words_vector = head_words_vectorizer.fit_transform(data_df.question_lemmatized.values).toarray()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLdL26_5NZE5"
      },
      "source": [
        "data_df[\"question_headwords\"] = data_df.processed_questions.apply(head_word_tokenizer)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm-PQAvCIv3i",
        "outputId": "ebdb2b9d-785e-44a0-c85e-f5d7a0dbe889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data_df[\"question_headwords\"]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   [things, are, we, do]\n",
              "1       [companies, are, which, organize]\n",
              "2                 [it, Is, traveller, go]\n",
              "3                           [places, are]\n",
              "4             [places, are, family, stay]\n",
              "                      ...                \n",
              "4995                           [area, is]\n",
              "4996                          [bars, are]\n",
              "4997                        [hotels, are]\n",
              "4998                                   []\n",
              "4999                             [it, Is]\n",
              "Name: question_headwords, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2bRZE1vM0Nt"
      },
      "source": [
        "## Headword Synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJicP4KJMzQz"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def wordnet_synonyms(keywords):\n",
        "  synonyms = []\n",
        "  for keyword in keywords:\n",
        "    for synset in wordnet.synsets(keyword):\n",
        "      for lemma in synset.lemmas():\n",
        "          synonyms.append(lemma.name())\n",
        "\n",
        "  return synonyms"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwbxc9OwgFpT",
        "outputId": "14f67ef4-c218-468e-b33b-bcd10234882b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "wordnet_synonyms([\"mother\", \"father\"])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mother',\n",
              " 'female_parent',\n",
              " 'mother',\n",
              " 'mother',\n",
              " 'mother',\n",
              " 'mother',\n",
              " 'mother',\n",
              " 'fuss',\n",
              " 'overprotect',\n",
              " 'beget',\n",
              " 'get',\n",
              " 'engender',\n",
              " 'father',\n",
              " 'mother',\n",
              " 'sire',\n",
              " 'generate',\n",
              " 'bring_forth',\n",
              " 'father',\n",
              " 'male_parent',\n",
              " 'begetter',\n",
              " 'forefather',\n",
              " 'father',\n",
              " 'sire',\n",
              " 'Father',\n",
              " 'Padre',\n",
              " 'Church_Father',\n",
              " 'Father_of_the_Church',\n",
              " 'Father',\n",
              " 'father',\n",
              " 'Father',\n",
              " 'Father-God',\n",
              " 'Fatherhood',\n",
              " 'founder',\n",
              " 'beginner',\n",
              " 'founding_father',\n",
              " 'father',\n",
              " 'don',\n",
              " 'father',\n",
              " 'beget',\n",
              " 'get',\n",
              " 'engender',\n",
              " 'father',\n",
              " 'mother',\n",
              " 'sire',\n",
              " 'generate',\n",
              " 'bring_forth']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBgZ_zb_O_dG"
      },
      "source": [
        "data_df[\"question_hw_syn\"] = data_df.question_headwords.apply(wordnet_synonyms)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1DghO5uQoCO",
        "outputId": "84177e96-f232-488c-d0ee-414cefdaa48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data_df[\"question_hw_syn\"]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [things, thing, thing, thing, thing, thing, ma...\n",
              "1       [company, company, company, companionship, fel...\n",
              "2       [information_technology, IT, be, be, be, exist...\n",
              "3       [topographic_point, place, spot, place, proper...\n",
              "4       [topographic_point, place, spot, place, proper...\n",
              "                              ...                        \n",
              "4995    [area, country, area, area, region, sphere, do...\n",
              "4996    [parallel_bars, bars, barroom, bar, saloon, gi...\n",
              "4997    [hotel, are, ar, be, be, be, exist, be, be, eq...\n",
              "4998                                                   []\n",
              "4999    [information_technology, IT, be, be, be, exist...\n",
              "Name: question_hw_syn, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dBspaFRkwnt"
      },
      "source": [
        "## Bag of Words\n",
        "This will be added to the training model directly using countVector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bup7Ki4DYSPn"
      },
      "source": [
        "# Vectorize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMbiobVajow5"
      },
      "source": [
        "## TF IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZACwC72YPhQ",
        "outputId": "417305f1-2e18-4077-a3dd-07e35b477b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_vectorize(text):\n",
        "  tfidfconverter = TfidfVectorizer(max_features=1500, min_df=1, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "  X = tfidfconverter.fit_transform(text).toarray()\n",
        "  return X\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8OnZAXmjtxW"
      },
      "source": [
        "## Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASqJypTvagpv",
        "outputId": "6ba40e9c-54d5-4034-dd81-223e9c232637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "def count_vectorize(text):\n",
        "  vectorizer = CountVectorizer(max_features=1500, min_df=1, max_df=0.7, stop_words=stopwords.words('english'))\n",
        "  X = vectorizer.fit_transform(text).toarray()\n",
        "  return X\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 1, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}